{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Information","metadata":{"id":"CrYJAcPMbJz1"}},{"cell_type":"markdown","source":"*  Context\n\nCollection of documents and its emotions\n\n*  Example\n\ni feel sick;sadness\n\n*  Goal\n\nWhen do people use positive emojis when they are texting?","metadata":{"id":"Y5JhLpuYbTpD"}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport math\nimport mlxtend\nimport sklearn.cluster as cluster\nimport sklearn.neighbors\nimport sklearn.metrics as metrics\nimport re\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport string\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import classification_report,confusion_matrix, roc_curve, auc, precision_score, recall_score, f1_score, precision_recall_curve\nimport nltk\nnltk.download('wordnet')\nnltk.download('stopwords')\nfrom nltk.tokenize import word_tokenize \nfrom nltk.tokenize import RegexpTokenizer\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-10-21T15:15:25.549029Z","iopub.execute_input":"2021-10-21T15:15:25.549638Z","iopub.status.idle":"2021-10-21T15:16:06.308426Z","shell.execute_reply.started":"2021-10-21T15:15:25.549477Z","shell.execute_reply":"2021-10-21T15:16:06.307344Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Load and explore the data\n#### The data is available at this source, and you can learn more about how and why this dataset is created from this paper.\nData source: https://www.kaggle.com/praveengovi/emotions-dataset-for-nlp ","metadata":{"id":"AYsKygirDHXw"}},{"cell_type":"code","source":"train_data = pd.read_csv('../input/emotions-dataset-for-nlp/train.txt',names=['sentence','emotion'],header=None, sep=';')\ntest_data = pd.read_csv('../input/emotions-dataset-for-nlp/test.txt',names=['sentence','emotion'],header=None, sep=';')\nval_data= pd.read_csv('../input/emotions-dataset-for-nlp/val.txt',names=['sentence','emotion'],header=None, sep=';')\ndf = pd.concat([train_data,test_data, val_data])\nprint('Total data:',df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-21T17:12:15.457347Z","iopub.execute_input":"2021-10-21T17:12:15.457692Z","iopub.status.idle":"2021-10-21T17:12:15.545520Z","shell.execute_reply.started":"2021-10-21T17:12:15.457655Z","shell.execute_reply":"2021-10-21T17:12:15.544423Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"# Null Check\ntrain_data.isnull().sum()\ntest_data.isnull().sum()\nval_data.isnull().sum()","metadata":{"id":"K-Rc1a0xPAbz","outputId":"8e42c51c-a1f9-4e46-9402-cee9fa2d447a","execution":{"iopub.status.busy":"2021-10-21T15:16:56.088160Z","iopub.execute_input":"2021-10-21T15:16:56.088504Z","iopub.status.idle":"2021-10-21T15:16:56.105782Z","shell.execute_reply.started":"2021-10-21T15:16:56.088464Z","shell.execute_reply":"2021-10-21T15:16:56.104727Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df = df.drop_duplicates(keep=\"first\") # Drop duplicated data and reindex the data\ndf_reidx = df.reset_index(drop=True)\ndf_reidx.shape","metadata":{"id":"geUnupErPFz2","outputId":"dc7d4a9f-9787-4400-f850-f16d3ba9c4e4","execution":{"iopub.status.busy":"2021-10-21T17:12:25.096126Z","iopub.execute_input":"2021-10-21T17:12:25.096653Z","iopub.status.idle":"2021-10-21T17:12:25.127296Z","shell.execute_reply.started":"2021-10-21T17:12:25.096602Z","shell.execute_reply":"2021-10-21T17:12:25.126723Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"# convert the emotions to binary labels. love and joy emotions are 1, and sadness, anger, fear, and surprise are 0.\ndf_reidx['label']=df_reidx['emotion'].replace({'joy':1, 'love': 1, \n                                   'sadness':0, 'anger':0, 'fear':0,'surprise':0})","metadata":{"id":"K_Z9aL_vm5f9","execution":{"iopub.status.busy":"2021-10-21T17:12:27.530881Z","iopub.execute_input":"2021-10-21T17:12:27.531496Z","iopub.status.idle":"2021-10-21T17:12:27.547760Z","shell.execute_reply.started":"2021-10-21T17:12:27.531457Z","shell.execute_reply":"2021-10-21T17:12:27.546917Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"# check if pos and neg sentiments\ndf_reidx.label.value_counts()","metadata":{"id":"jqlwmw4XbpjL","outputId":"19b3706c-25ff-4552-ca0f-5e6b7a74e86d","execution":{"iopub.status.busy":"2021-10-21T15:17:44.702522Z","iopub.execute_input":"2021-10-21T15:17:44.702868Z","iopub.status.idle":"2021-10-21T15:17:44.711071Z","shell.execute_reply.started":"2021-10-21T15:17:44.702830Z","shell.execute_reply":"2021-10-21T15:17:44.710422Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df_reidx['length'] = df_reidx['sentence'].apply(len) # number of characters\ndf_reidx['length'].describe() # info()","metadata":{"id":"YjHjxw4LdIsg","outputId":"ed749b95-82d3-47ab-f473-91b257eb0322","execution":{"iopub.status.busy":"2021-10-21T15:17:46.486777Z","iopub.execute_input":"2021-10-21T15:17:46.487820Z","iopub.status.idle":"2021-10-21T15:17:46.506628Z","shell.execute_reply.started":"2021-10-21T15:17:46.487767Z","shell.execute_reply":"2021-10-21T15:17:46.506001Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df_reidx.tail()","metadata":{"execution":{"iopub.status.busy":"2021-10-21T17:12:30.287761Z","iopub.execute_input":"2021-10-21T17:12:30.288111Z","iopub.status.idle":"2021-10-21T17:12:30.303552Z","shell.execute_reply.started":"2021-10-21T17:12:30.288069Z","shell.execute_reply":"2021-10-21T17:12:30.302387Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"markdown","source":"# Text Preprocessing\n#### To clean the sentences,we do text preprocessing.","metadata":{"id":"KptVLKp2dtfr"}},{"cell_type":"markdown","source":"*   Decontracted\n*   Data cleaning\nAdditionally,\n*   Spell check\n*   Lemmatization\n*   Nomalization\n\n\n\n","metadata":{"id":"UX36yQrhd35L"}},{"cell_type":"code","source":"from tqdm import tqdm\nimport re\nfrom bs4 import BeautifulSoup\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\n\ndef decontracted(phrase):\n    \"\"\"\n    We first define a function to expand the contracted phrase into normal words\n    \"\"\"\n    # specific\n    phrase = re.sub(r\"wont\", \"will not\", phrase)\n    phrase = re.sub(r\"wouldnt\", \"would not\", phrase)\n    phrase = re.sub(r\"shouldnt\", \"should not\", phrase)\n    phrase = re.sub(r\"couldnt\", \"could not\", phrase)\n    phrase = re.sub(r\"cudnt\", \"could not\", phrase)\n    phrase = re.sub(r\"cant\", \"can not\", phrase)\n    phrase = re.sub(r\"dont\", \"do not\", phrase)\n    phrase = re.sub(r\"doesnt\", \"does not\", phrase)\n    phrase = re.sub(r\"didnt\", \"did not\", phrase)\n    phrase = re.sub(r\"wasnt\", \"was not\", phrase)\n    phrase = re.sub(r\"werent\", \"were not\", phrase)\n    phrase = re.sub(r\"havent\", \"have not\", phrase)\n    phrase = re.sub(r\"hadnt\", \"had not\", phrase)\n\n    # general\n    phrase = re.sub(r\"n\\ t\", \" not\", phrase)\n    #phrase = re.sub(r\"\\re\", \" are\", phrase)\n    phrase = re.sub(r\"\\ s \", \" is \", phrase) # prime \n    phrase = re.sub(r\"\\ d \", \" would \", phrase)\n    phrase = re.sub(r\"\\ ll \", \" will \", phrase)\n    phrase = re.sub(r\"\\dunno\", \"do not \", phrase)\n    phrase = re.sub(r\"ive \", \"i have \", phrase)\n    phrase = re.sub(r\"im \", \"i am \", phrase)\n    phrase = re.sub(r\"i m \", \"i am \", phrase)\n    phrase = re.sub(r\" w \", \" with \", phrase)\n    \n    return phrase\n\n    \ndef clean_text(df):\n    \"\"\"\n    Clean the review texts\n    \"\"\"\n    cleaned_review = []\n\n    for review_text in tqdm(df['sentence']):\n        \n        # expand the contracted words\n        review_text = decontracted(review_text)\n        #remove html tags\n        review_text = BeautifulSoup(review_text, 'lxml').get_text().strip() # re.sub(r'<.*?>', '', text)\n        \n        #remove non-alphabetic characters\n        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n    \n        #remove url \n        review_text = re.sub(r'https?://\\S+|www\\.\\S+', '', review_text)\n        \n        #Removing punctutation, string.punctuation in python consists of !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_{|}~`\n        review_text = review_text.translate(str.maketrans('', '', string.punctuation))\n        # ''.join([char for char in movie_text_data if char not in string.punctuation])\n        \n        # remove emails\n        review_text = re.sub(r\"(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\", '', review_text)\n    \n        cleaned_review.append(review_text)\n\n    return cleaned_review  \n\ndf_reidx['cleaned_sentence'] = clean_text(df_reidx)\ndf_reidx.head()  ","metadata":{"id":"RTfGwvFpes_X","outputId":"dd06810a-eefc-4333-99b5-7b8f29afcca3","execution":{"iopub.status.busy":"2021-10-21T17:30:38.715679Z","iopub.execute_input":"2021-10-21T17:30:38.716383Z","iopub.status.idle":"2021-10-21T17:30:44.263219Z","shell.execute_reply.started":"2021-10-21T17:30:38.716343Z","shell.execute_reply":"2021-10-21T17:30:44.262279Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"markdown","source":"###### additional lemmatization","metadata":{"id":"NWRKxc1vECx0"}},{"cell_type":"code","source":"def remove_stopwords(phrase):\n    remove_sw = []\n    tokenizer = RegexpTokenizer(r'[a-zA-Z0-9]+')\n    stop_words = stopwords.words('english')\n    \n    for review_text in tqdm(phrase):\n        tokens = word_tokenize(review_text)\n        tokens = [word for word in tokens if not word in stop_words]\n        remove_sw.append(tokens)\n    return remove_sw\n\ndf_reidx['cleaned_sentence'] = remove_stopwords(df_reidx['cleaned_sentence'])\ndf_reidx.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-21T17:30:45.860627Z","iopub.execute_input":"2021-10-21T17:30:45.861063Z","iopub.status.idle":"2021-10-21T17:30:49.009644Z","shell.execute_reply.started":"2021-10-21T17:30:45.861013Z","shell.execute_reply":"2021-10-21T17:30:49.008552Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"#stemming for extract the actual meaning of the words\nfrom nltk.stem import PorterStemmer\n\ndef stemming(phrase):\n    stemmer = PorterStemmer()\n    stem_output=[]\n    stemmed=[]\n    for review_text in tqdm(phrase):\n        stemmed = [stemmer.stem(word) for word in review_text]\n        stem_output.append(stemmed)\n    return stem_output\n\ndf_reidx['cleaned_sentence'] = stemming(df_reidx['cleaned_sentence'])\ndf_reidx['cleaned_sentence'].head()","metadata":{"id":"UdFbKacIgGU_","outputId":"f782280a-d80c-4862-88b7-b340a9b4db04","execution":{"iopub.status.busy":"2021-10-21T17:30:56.521195Z","iopub.execute_input":"2021-10-21T17:30:56.521496Z","iopub.status.idle":"2021-10-21T17:31:00.497871Z","shell.execute_reply.started":"2021-10-21T17:30:56.521464Z","shell.execute_reply":"2021-10-21T17:31:00.496933Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"def to_sentence(phrase):\n    sentence=[]\n    for words in tqdm(phrase):\n        sentence.append((\" \").join(words))\n    return sentence\ndf_reidx['cleaned_sentence']=to_sentence(df_reidx['cleaned_sentence'])\ndf_reidx['cleaned_sentence'].head()","metadata":{"execution":{"iopub.status.busy":"2021-10-21T17:31:10.038641Z","iopub.execute_input":"2021-10-21T17:31:10.038954Z","iopub.status.idle":"2021-10-21T17:31:10.079436Z","shell.execute_reply.started":"2021-10-21T17:31:10.038924Z","shell.execute_reply":"2021-10-21T17:31:10.078788Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{"id":"tt6Tbl3xlBhE"}},{"cell_type":"markdown","source":"### CounterVectorize: tokenization: ","metadata":{"id":"Ln-1lwjhlfS7"}},{"cell_type":"code","source":"# convert the cleaned sentences to vectors\ntoken = RegexpTokenizer(r'[a-zA-Z0-9]+')\n# a built-in stop word list for english is used\n# all values of n such than min_n<=n<= max_n will be used. (1,1): only unigrams, (1,2):uni&bigram, (2,2): only bigrams\n# max_df: when building the vocabulary, ignore terms that have a document frequency strictly higher than the given threshold.\n# min_df: ignore terms that have a document frequency strictly lower than the given threshold.\n\nvectorizer = CountVectorizer(stop_words='english', max_df=0.5, min_df=3, ngram_range=(1,1),tokenizer = token.tokenize)\nx = vectorizer.fit_transform(df_reidx.cleaned_sentence)\ny = df_reidx.label.values\n\nprint(\"X.shape : \",x.shape)\nprint(\"y.shape : \",y.shape)","metadata":{"id":"jT3nRcj9v-mL","outputId":"278e3b54-b1c7-4b5c-8a3c-3da1f6fce5a0","execution":{"iopub.status.busy":"2021-10-21T17:31:13.436234Z","iopub.execute_input":"2021-10-21T17:31:13.436540Z","iopub.status.idle":"2021-10-21T17:31:13.665953Z","shell.execute_reply.started":"2021-10-21T17:31:13.436505Z","shell.execute_reply":"2021-10-21T17:31:13.664986Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"markdown","source":"# Train Test split\n\n```\n# This is formatted as code\n```\n\n","metadata":{"id":"l1kNPsDNm_f4"}},{"cell_type":"code","source":"# do shuffle to make neg and pos data of data set split equaly in the test and training set\n# do random_sate for making it settle when we run this code repeatedly\ntrain_idx, test_idx = train_test_split(np.arange(df_reidx.shape[0]), test_size=0.3,shuffle=True, random_state=42)\n\nx_train = x[train_idx]\ny_train = y[train_idx]\n\nx_test = x[test_idx]\ny_test = y[test_idx]\nprint(\"Number of training examples:{}\".format(len(train_idx)))\nprint(\"Number of testing examples:{}\\n\".format(len(test_idx)))\nprint(\"Training data: X_train : {}, y_train : {}\".format(x_train.shape, y_train.shape))\nprint(\"Testing data: X_test : {}, y_test : {}\".format(x_test.shape, y_test.shape))\n","metadata":{"id":"OqtP1s3WnOEj","outputId":"eb5ed0cd-d174-4fdf-be65-0594b3f056d1","execution":{"iopub.status.busy":"2021-10-21T17:31:19.273228Z","iopub.execute_input":"2021-10-21T17:31:19.273529Z","iopub.status.idle":"2021-10-21T17:31:19.287075Z","shell.execute_reply.started":"2021-10-21T17:31:19.273496Z","shell.execute_reply":"2021-10-21T17:31:19.286374Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"x_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-21T17:31:21.546773Z","iopub.execute_input":"2021-10-21T17:31:21.547442Z","iopub.status.idle":"2021-10-21T17:31:21.554046Z","shell.execute_reply.started":"2021-10-21T17:31:21.547390Z","shell.execute_reply":"2021-10-21T17:31:21.553166Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{"id":"m1fK2NLdzysQ"}},{"cell_type":"markdown","source":"#### Logistic Regression","metadata":{"id":"Dwtb2azVm2U8"}},{"cell_type":"code","source":"# fit a logistic regression classifier on the training data use default settings\nlr_clf = LogisticRegression()\nlr_clf.fit(x_train, y_train)\n\n# make prediction on testing data\ny_pred_test_lr = lr_clf.predict(x_test)\ny_predprob_lr = lr_clf.predict_proba(x_test)\nmatrix_lr = confusion_matrix(y_test,y_pred_test_lr)\nprint(matrix_lr)","metadata":{"id":"2gfpybeIm7NX","outputId":"7e66a289-1c74-49cc-8442-6bdf6e212877","execution":{"iopub.status.busy":"2021-10-21T17:31:23.368646Z","iopub.execute_input":"2021-10-21T17:31:23.368948Z","iopub.status.idle":"2021-10-21T17:31:23.594120Z","shell.execute_reply.started":"2021-10-21T17:31:23.368918Z","shell.execute_reply":"2021-10-21T17:31:23.593177Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred_test_lr))","metadata":{"id":"HPpKaULGnAHz","outputId":"d483f0be-13a0-4fca-9de2-15bc4c35d3f6","execution":{"iopub.status.busy":"2021-10-21T17:31:26.036811Z","iopub.execute_input":"2021-10-21T17:31:26.037326Z","iopub.status.idle":"2021-10-21T17:31:26.060310Z","shell.execute_reply.started":"2021-10-21T17:31:26.037271Z","shell.execute_reply":"2021-10-21T17:31:26.059657Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"print(\"Accuracy for Logistic Regression model:\",metrics.accuracy_score(y_test, y_pred_test_lr))","metadata":{"id":"u1ccmDmjRcEg","outputId":"815aa552-f2e1-462e-c066-7009511231f3","execution":{"iopub.status.busy":"2021-10-21T17:31:28.336457Z","iopub.execute_input":"2021-10-21T17:31:28.337461Z","iopub.status.idle":"2021-10-21T17:31:28.344134Z","shell.execute_reply.started":"2021-10-21T17:31:28.337414Z","shell.execute_reply":"2021-10-21T17:31:28.343249Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"markdown","source":"#### Naive Bayes classifier","metadata":{"id":"IdXsV5VK78nt"}},{"cell_type":"markdown","source":"##### BernouliNB\n\nA binary algorithm used when the feature is present or not.","metadata":{"id":"-nRFJAe3opBp"}},{"cell_type":"code","source":"from sklearn.naive_bayes import BernoulliNB\nnb_clf = BernoulliNB()\nnb_clf.fit(x_train, y_train)\n# make prediction on testing data\ny_pred_test_nb = nb_clf.predict(x_test)\ny_predprob_nb = nb_clf.predict_proba(x_test)\nmatrix_nb = confusion_matrix(y_test,y_pred_test_nb)\nprint(matrix_nb)","metadata":{"id":"wLfvVX1_77P7","outputId":"960ed7f0-5bab-46dd-b842-872a51dc19de","execution":{"iopub.status.busy":"2021-10-21T17:31:32.103365Z","iopub.execute_input":"2021-10-21T17:31:32.103691Z","iopub.status.idle":"2021-10-21T17:31:32.127750Z","shell.execute_reply.started":"2021-10-21T17:31:32.103654Z","shell.execute_reply":"2021-10-21T17:31:32.127104Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"y_predprob_test_nb = nb_clf.predict_proba(x_test)\ny_predprob_test_nb","metadata":{"id":"IA2i42iM8JRo","outputId":"8fd40cf0-ada6-4260-ae02-09137f39e553","execution":{"iopub.status.busy":"2021-10-21T17:31:36.868759Z","iopub.execute_input":"2021-10-21T17:31:36.869663Z","iopub.status.idle":"2021-10-21T17:31:36.878658Z","shell.execute_reply.started":"2021-10-21T17:31:36.869624Z","shell.execute_reply":"2021-10-21T17:31:36.877982Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred_test_nb))\n# micro average (averaging the total true positives, false negatives and false positives globally, true pos of one class / (all true pos + all false pos))\n# macro average (averaging the unweighted mean per label)","metadata":{"id":"BH_Fzq9iqa3C","outputId":"ecabb18e-8643-44e7-834c-0a9b63d9e5bb","execution":{"iopub.status.busy":"2021-10-21T17:31:40.923951Z","iopub.execute_input":"2021-10-21T17:31:40.924275Z","iopub.status.idle":"2021-10-21T17:31:40.944834Z","shell.execute_reply.started":"2021-10-21T17:31:40.924239Z","shell.execute_reply":"2021-10-21T17:31:40.943759Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nprint(\"Accuracy for Bernouli Naive Bayes model:\",metrics.accuracy_score(y_test, y_pred_test_nb))","metadata":{"id":"cNnZGzgUAmCp","outputId":"9dcd39ae-4c5e-47d0-aa3e-49823c620051","execution":{"iopub.status.busy":"2021-10-21T17:32:00.937312Z","iopub.execute_input":"2021-10-21T17:32:00.938262Z","iopub.status.idle":"2021-10-21T17:32:00.945317Z","shell.execute_reply.started":"2021-10-21T17:32:00.938207Z","shell.execute_reply":"2021-10-21T17:32:00.944225Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"markdown","source":"##### MultinominaliNB\n\nIt consider a feature vector where a given term represents the number of times it appears or very ofen, such as frequency.","metadata":{"id":"i_3y0arSokl1"}},{"cell_type":"code","source":"mnb = MultinomialNB()\nmnb.fit(x_train, y_train)\n# make prediction on testing data\ny_pred_test_mnb = mnb.predict(x_test)\ny_predprob_mnb = mnb.predict_proba(x_test)\nmatrix = confusion_matrix(y_test,y_pred_test_mnb)\nprint(matrix)","metadata":{"id":"0szXmLlOphy3","outputId":"215ffbde-306d-484f-fcbd-2c7aee0c8059","execution":{"iopub.status.busy":"2021-10-21T17:32:02.558674Z","iopub.execute_input":"2021-10-21T17:32:02.559156Z","iopub.status.idle":"2021-10-21T17:32:02.579095Z","shell.execute_reply.started":"2021-10-21T17:32:02.559122Z","shell.execute_reply":"2021-10-21T17:32:02.578118Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred_test_mnb))","metadata":{"id":"pvUSyj-EpxVp","outputId":"5ef010a8-2c87-4639-c0fb-80a6db36427c","execution":{"iopub.status.busy":"2021-10-21T17:32:04.550980Z","iopub.execute_input":"2021-10-21T17:32:04.551437Z","iopub.status.idle":"2021-10-21T17:32:04.572214Z","shell.execute_reply.started":"2021-10-21T17:32:04.551400Z","shell.execute_reply":"2021-10-21T17:32:04.571195Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"print(\"Accuracy for multinominal Naive Bayes model:\",metrics.accuracy_score(y_test, y_pred_test_mnb))","metadata":{"id":"kf6X_WR1rUcq","outputId":"64521289-7dcf-4c8c-f592-afd6f5091f67","execution":{"iopub.status.busy":"2021-10-21T17:32:05.726654Z","iopub.execute_input":"2021-10-21T17:32:05.727012Z","iopub.status.idle":"2021-10-21T17:32:05.733899Z","shell.execute_reply.started":"2021-10-21T17:32:05.726974Z","shell.execute_reply":"2021-10-21T17:32:05.732870Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{"id":"abbE2gAG0YlS"}},{"cell_type":"markdown","source":"# Cross validataion","metadata":{"id":"rivuHvYu3FM-"}},{"cell_type":"markdown","source":"##### Logistic Regression","metadata":{"id":"drFvvZZ-phhG"}},{"cell_type":"code","source":"# n-fold cross validation\nscores_lr = cross_val_score(lr_clf, x, y, cv=5, scoring='precision')\nprint(scores_lr)","metadata":{"id":"Ns19AmQ2naXN","outputId":"2d1621ee-fd11-4f00-d0de-ac4d194cc64f","execution":{"iopub.status.busy":"2021-10-21T17:32:10.082990Z","iopub.execute_input":"2021-10-21T17:32:10.083484Z","iopub.status.idle":"2021-10-21T17:32:11.323081Z","shell.execute_reply.started":"2021-10-21T17:32:10.083432Z","shell.execute_reply":"2021-10-21T17:32:11.322043Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"markdown","source":"##### BernouliNB","metadata":{"id":"e5nbe_IzoH1T"}},{"cell_type":"code","source":"scores_nb = cross_val_score(nb_clf, x, y, cv=5, scoring='precision')\nprint(scores_nb)","metadata":{"id":"cpevzJJ1-sTu","outputId":"82153c78-174c-438a-8ea5-5d4ecba70276","execution":{"iopub.status.busy":"2021-10-21T17:32:14.956590Z","iopub.execute_input":"2021-10-21T17:32:14.956914Z","iopub.status.idle":"2021-10-21T17:32:15.024067Z","shell.execute_reply.started":"2021-10-21T17:32:14.956879Z","shell.execute_reply":"2021-10-21T17:32:15.022804Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"markdown","source":"##### MultinominaliNB","metadata":{"id":"h5yFEWAeoTlt"}},{"cell_type":"code","source":"scores_mnb = cross_val_score(mnb, x, y, cv=5, scoring='precision')\nprint(scores_mnb)","metadata":{"id":"BRVfVfaRrOXE","outputId":"9f7b9b65-cb74-4a23-a16d-613fae557f09","execution":{"iopub.status.busy":"2021-10-21T17:32:17.373987Z","iopub.execute_input":"2021-10-21T17:32:17.374274Z","iopub.status.idle":"2021-10-21T17:32:17.428770Z","shell.execute_reply.started":"2021-10-21T17:32:17.374242Z","shell.execute_reply":"2021-10-21T17:32:17.428044Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"markdown","source":"##### ROC Curve","metadata":{"id":"R-4-ViPgri7h"}},{"cell_type":"markdown","source":"##### Logistic Regression","metadata":{"id":"1drwLQ9hpmca"}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\n\nfpr, tpr, thresholds = roc_curve(y_true = y_test, y_score = y_predprob_lr[:,1], pos_label=1)\nroc_auc = auc(fpr, tpr) # area under ROC curve\n\nplt.figure()\nlw = 2\nplt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC (Receiver operating characteristic) curve')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"id":"QdnCc7PjnfZw","outputId":"df2f3a1b-155c-40bc-e343-c37e20453b48","execution":{"iopub.status.busy":"2021-10-21T17:32:20.750629Z","iopub.execute_input":"2021-10-21T17:32:20.751552Z","iopub.status.idle":"2021-10-21T17:32:21.007010Z","shell.execute_reply.started":"2021-10-21T17:32:20.751513Z","shell.execute_reply":"2021-10-21T17:32:21.005905Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"markdown","source":"##### BernouliNB","metadata":{"id":"uX-VWSHMtu27"}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\n\nfpr, tpr, thresholds = roc_curve(y_true = y_test, y_score = y_predprob_nb[:,1], pos_label=1)\nroc_auc = auc(fpr, tpr) # area under ROC curve\n\nplt.figure()\nlw = 2\nplt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC (Receiver operating characteristic) curve')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"id":"zSGj64AMt0IY","outputId":"30d195ee-1e07-49db-c53b-5381c867e781","execution":{"iopub.status.busy":"2021-10-21T17:32:23.181834Z","iopub.execute_input":"2021-10-21T17:32:23.182155Z","iopub.status.idle":"2021-10-21T17:32:23.403990Z","shell.execute_reply.started":"2021-10-21T17:32:23.182121Z","shell.execute_reply":"2021-10-21T17:32:23.403015Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"markdown","source":"##### MultinominaliNB","metadata":{"id":"FiOW8B9joVXv"}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\n\nfpr, tpr, thresholds = roc_curve(y_true = y_test, y_score = y_predprob_mnb[:,1], pos_label=1)\nroc_auc = auc(fpr, tpr) # area under ROC curve\n\nplt.figure()\nlw = 2\nplt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC (Receiver operating characteristic) curve')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"id":"lKYhef6srlAf","outputId":"18c2fbc5-e86f-4a84-ca34-28d233edc770","execution":{"iopub.status.busy":"2021-10-21T17:32:25.208787Z","iopub.execute_input":"2021-10-21T17:32:25.209099Z","iopub.status.idle":"2021-10-21T17:32:25.423617Z","shell.execute_reply.started":"2021-10-21T17:32:25.209067Z","shell.execute_reply":"2021-10-21T17:32:25.422734Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"markdown","source":"### Precision Recall Curve","metadata":{"id":"Vmy0gGdftj4Q"}},{"cell_type":"markdown","source":"##### Logistic Regression","metadata":{"id":"YKzqXuuJtn3g"}},{"cell_type":"code","source":"from sklearn.metrics import average_precision_score\nprecision, recall, thresholds = precision_recall_curve(y_true=y_test, probas_pred=y_predprob_lr[:,1], pos_label=1)\nplt.plot(recall, precision, color='darkorange', lw=lw, label='Average precision recall score: %0.2f' % average_precision_score(y_test, y_predprob_mnb[:,1]))\n\nplt.title('Precision recall curve')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.legend()\nplt.show()","metadata":{"id":"NRRbVPDynnBt","outputId":"260e1de6-e2c6-498d-a0de-84c5b1f4f6cf","execution":{"iopub.status.busy":"2021-10-21T17:32:27.878364Z","iopub.execute_input":"2021-10-21T17:32:27.878875Z","iopub.status.idle":"2021-10-21T17:32:28.110823Z","shell.execute_reply.started":"2021-10-21T17:32:27.878823Z","shell.execute_reply":"2021-10-21T17:32:28.109767Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"markdown","source":"##### BernouliNB","metadata":{"id":"HLorE4Axtstz"}},{"cell_type":"code","source":"from sklearn.metrics import average_precision_score\nprecision, recall, thresholds = precision_recall_curve(y_true=y_test, probas_pred=y_predprob_nb[:,1], pos_label=1)\nplt.plot(recall, precision, color='darkorange', lw=lw, label='Average precision recall score: %0.2f' % average_precision_score(y_test, y_predprob_mnb[:,1]))\n\nplt.title('Precision recall curve')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.legend()\nplt.show()","metadata":{"id":"RvmZahxRt7R4","outputId":"0555682a-4df1-4c52-b36a-66a323d4283a","execution":{"iopub.status.busy":"2021-10-21T17:32:30.301757Z","iopub.execute_input":"2021-10-21T17:32:30.302068Z","iopub.status.idle":"2021-10-21T17:32:30.532846Z","shell.execute_reply.started":"2021-10-21T17:32:30.302035Z","shell.execute_reply":"2021-10-21T17:32:30.531691Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"markdown","source":"##### MultinominaliNB","metadata":{"id":"Fvc31icpoW3l"}},{"cell_type":"code","source":"from sklearn.metrics import average_precision_score\nprecision, recall, thresholds = precision_recall_curve(y_true=y_test, probas_pred=y_predprob_mnb[:,1], pos_label=1)\nplt.plot(recall, precision, color='darkorange', lw=lw, label='Average precision recall score: %0.2f' % average_precision_score(y_test, y_predprob_mnb[:,1]))\n\nplt.title('Precision recall curve')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.legend()\nplt.show()","metadata":{"id":"N3b3ggnHshK2","outputId":"1d225feb-794b-49b3-f908-5fb78d1e339e","execution":{"iopub.status.busy":"2021-10-21T17:32:32.360171Z","iopub.execute_input":"2021-10-21T17:32:32.360674Z","iopub.status.idle":"2021-10-21T17:32:32.593306Z","shell.execute_reply.started":"2021-10-21T17:32:32.360615Z","shell.execute_reply":"2021-10-21T17:32:32.592096Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"markdown","source":"###### LinearRegression","metadata":{"id":"jCdAQQk5n9Lu"}},{"cell_type":"code","source":"acc_score_lr = metrics.accuracy_score(y_pred_test_lr,y_test)\nprec_score_lr = precision_score(y_test,y_pred_test_lr, average='macro')\nrecall_lr = recall_score(y_test, y_pred_test_lr,average='macro')\nf1_lr = f1_score(y_test,y_pred_test_nb,average='macro')\nmatrix_lr = confusion_matrix(y_test,y_pred_test_lr)\nprint('Logistic Regression Model\\n')\nprint(str('Accuracy: '+'{:04.2f}'.format(acc_score_lr*100))+'%')\nprint(str('Precision: '+'{:04.2f}'.format(prec_score_lr*100))+'%')\nprint(str('Recall: '+'{:04.2f}'.format(recall_lr*100))+'%')\nprint('F1 Score: ',f1_lr)\nprint(matrix_lr)","metadata":{"id":"kO0UOIPNnsaZ","outputId":"21994a37-3793-4c2d-c8d6-7cac3a026da4","execution":{"iopub.status.busy":"2021-10-21T17:32:34.197930Z","iopub.execute_input":"2021-10-21T17:32:34.198656Z","iopub.status.idle":"2021-10-21T17:32:34.221661Z","shell.execute_reply.started":"2021-10-21T17:32:34.198613Z","shell.execute_reply":"2021-10-21T17:32:34.220991Z"},"trusted":true},"execution_count":147,"outputs":[]},{"cell_type":"markdown","source":"##### BernouliNB","metadata":{"id":"av7z4Hnzn_aw"}},{"cell_type":"code","source":"acc_score_nb = metrics.accuracy_score(y_pred_test_nb,y_test)\nprec_score_nb = precision_score(y_test,y_pred_test_nb, average='macro')\nrecall_nb = recall_score(y_test, y_pred_test_nb,average='macro')\nf1_nb = f1_score(y_test,y_pred_test_nb,average='macro')\nmatrix_nb = confusion_matrix(y_test,y_pred_test_nb)\nprint('Bernouli Naive Bayes Model\\n')\nprint(str('Accuracy: '+'{:04.2f}'.format(acc_score_nb*100))+'%')\nprint(str('Precision: '+'{:04.2f}'.format(prec_score_nb*100))+'%')\nprint(str('Recall: '+'{:04.2f}'.format(recall_nb*100))+'%')\nprint('F1 Score: ',f1_nb)\nprint(matrix_nb)","metadata":{"id":"BL4jUTnHwQAA","outputId":"6e2d2cc2-4718-44ea-f937-4fb59c4a760d","execution":{"iopub.status.busy":"2021-10-21T17:32:40.401893Z","iopub.execute_input":"2021-10-21T17:32:40.402598Z","iopub.status.idle":"2021-10-21T17:32:40.427641Z","shell.execute_reply.started":"2021-10-21T17:32:40.402543Z","shell.execute_reply":"2021-10-21T17:32:40.426904Z"},"trusted":true},"execution_count":148,"outputs":[]},{"cell_type":"markdown","source":"##### MultinominaliNB","metadata":{"id":"0_SSgCmHoX3p"}},{"cell_type":"code","source":"acc_score_mnb = metrics.accuracy_score(y_pred_test_mnb,y_test)\nprec_score_mnb = precision_score(y_test,y_pred_test_mnb, average='macro')\nrecall_mnb = recall_score(y_test, y_pred_test_mnb,average='macro')\nf1_mnb = f1_score(y_test,y_pred_test_mnb,average='macro')\nmatrix_mnb = confusion_matrix(y_test,y_pred_test_mnb)\nprint('Multimominal Naive Bayes Model\\n')\nprint(str('Accuracy: '+'{:04.2f}'.format(acc_score_mnb*100))+'%')\nprint(str('Precision: '+'{:04.2f}'.format(prec_score_mnb*100))+'%')\nprint(str('Recall: '+'{:04.2f}'.format(recall_mnb*100))+'%')\nprint('F1 Score: ',f1_mnb)\nprint(matrix_mnb)","metadata":{"id":"nwGHeF5Xv60e","outputId":"d3cc673f-8ff9-4614-e343-614e7205edc0","execution":{"iopub.status.busy":"2021-10-21T17:32:44.383275Z","iopub.execute_input":"2021-10-21T17:32:44.383759Z","iopub.status.idle":"2021-10-21T17:32:44.410115Z","shell.execute_reply.started":"2021-10-21T17:32:44.383698Z","shell.execute_reply":"2021-10-21T17:32:44.409306Z"},"trusted":true},"execution_count":149,"outputs":[]},{"cell_type":"markdown","source":"# Grid Search for parameter tuning","metadata":{"id":"Jf7nJ4yiEfh6"}},{"cell_type":"markdown","source":"##### Logistic Regression parameter tuning","metadata":{"id":"OdzklJ8jLljW"}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV  #predefined hyperparameters and fit your estimator (model) on your training set.\nfrom sklearn.pipeline import Pipeline\n\nvector = CountVectorizer(stop_words='english')\nlogistic = LogisticRegression() # , tol=0.1\n\n# build a pipeline\npipe = Pipeline(steps = [\n       ('vectorizer', vector),\n       ('classifier', logistic)])\n\n# creat a dictionary of model parameters and corresponding values\n# For example, in countvectorizer, we want to explore the suitable value for min_df, select from 1,3,5,10\nparam_grid = {\n    'vectorizer__min_df': [1, 3, 5, 10],\n    'vectorizer__max_df': [0.7, 0.8, 0.9],\n    'classifier__penalty': ['l1','l2']}\n\n# run GridSearchCV, cv, f1\nsearch_result = GridSearchCV(pipe, param_grid, cv=5, scoring='f1').fit(df_reidx.cleaned_sentence.values, df_reidx.label.values)\n\nprint(\"Best parameter (CV score=%0.3f):\" % search_result.best_score_) # scoring: accuracy by default\nprint(search_result.best_params_)\n# with 5 fold cv, the best f1 score is 0.958, and the corresponding parameter values are as follows:","metadata":{"id":"I224l6uLEfRo","outputId":"531b0d0b-afc2-4fbd-bdf3-22ed6727f506","execution":{"iopub.status.busy":"2021-10-21T17:32:47.974641Z","iopub.execute_input":"2021-10-21T17:32:47.975197Z","iopub.status.idle":"2021-10-21T17:33:32.744787Z","shell.execute_reply.started":"2021-10-21T17:32:47.975145Z","shell.execute_reply":"2021-10-21T17:33:32.743629Z"},"trusted":true},"execution_count":150,"outputs":[]},{"cell_type":"markdown","source":"##### Bernoulli Naive Bayes parameter tuning","metadata":{"id":"Bl7hXH4uLpp5"}},{"cell_type":"code","source":"vector = CountVectorizer(stop_words='english')\nlogistic = BernoulliNB() # , tol=0.1\n\n# build a pipeline\npipe = Pipeline(steps = [\n       ('vectorizer', vector),\n       ('classifier', logistic)])\nparameters = {'vectorizer__min_df': [1, 3, 5, 10],\n    'vectorizer__max_df': [0.7, 0.8, 0.9],\n    'classifier__alpha':[0.0, 0.1, 1.0, 2.0, 10.0]}\n\n# run GridSearchCV, cv, f1    \nsearch_result = GridSearchCV(pipe, parameters, cv=5, scoring='f1').fit(df_reidx.cleaned_sentence.values, df_reidx.label.values)\n\nprint(\"Best parameter (CV score=%0.3f):\" % search_result.best_score_) \nprint(search_result.best_params_)\n# with 5 fold cv, the best f1 score is 0.943, and the corresponding parameter values are as follows:","metadata":{"id":"RSCJlHXDJBvt","outputId":"c0093bc8-fe3f-4862-b7c2-aef265a84917","execution":{"iopub.status.busy":"2021-10-21T17:33:41.379514Z","iopub.execute_input":"2021-10-21T17:33:41.379838Z","iopub.status.idle":"2021-10-21T17:34:51.281376Z","shell.execute_reply.started":"2021-10-21T17:33:41.379804Z","shell.execute_reply":"2021-10-21T17:34:51.280215Z"},"trusted":true},"execution_count":151,"outputs":[]},{"cell_type":"markdown","source":"##### Multinomial Naive Bayes parameter tuning","metadata":{"id":"Z8VtJskkLuQQ"}},{"cell_type":"code","source":"vector = CountVectorizer(stop_words='english')\nlogistic = MultinomialNB() # , tol=0.1\n\n# build a pipeline\npipe = Pipeline(steps = [\n       ('vectorizer', vector),\n       ('classifier', logistic)])\nparameters = {'vectorizer__min_df': [1, 3, 5, 10],\n    'vectorizer__max_df': [0.7, 0.8, 0.9],\n    'classifier__alpha':[0.0, 0.1, 1.0, 2.0, 10.0]}\n\n# run GridSearchCV, cv, f1    \nsearch_result = GridSearchCV(pipe, parameters, cv=5, scoring='f1').fit(df_reidx.cleaned_sentence.values, df_reidx.label.values)\n\nprint(\"Best parameter (CV score=%0.3f):\" % search_result.best_score_) \nprint(search_result.best_params_)\n# with 5 fold cv, the best f1 score is 0.942, and the corresponding parameter values are as follows:","metadata":{"id":"T0rLawW9Fn2S","outputId":"0689a830-25cf-44cb-9388-cddedc765255","execution":{"iopub.status.busy":"2021-10-21T17:34:56.066750Z","iopub.execute_input":"2021-10-21T17:34:56.067065Z","iopub.status.idle":"2021-10-21T17:36:06.673456Z","shell.execute_reply.started":"2021-10-21T17:34:56.067032Z","shell.execute_reply":"2021-10-21T17:36:06.671682Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"markdown","source":"# Explain the model prediction","metadata":{"id":"SYMdylft3xEx"}},{"cell_type":"markdown","source":"Multimominal Naive Bayes Model has higher accuracy than Bernouli Naive Bayes Model. And Logistic Regression model has the highest accuracy than others, so I chose Logistic Regression model to test the model.","metadata":{"id":"35GU2wpCwukP"}},{"cell_type":"code","source":"test_data = df_reidx.iloc[test_idx]\ntest_data['pred_label'] = y_pred_test_lr\ntest_data.head(2)[['sentence','label','pred_label']]\n# shows what the prediction label fit to the real label","metadata":{"id":"Y-Td0j-j3zyl","outputId":"68a8f57e-7364-479f-a9e7-191cad88c951","execution":{"iopub.status.busy":"2021-10-21T17:36:10.068741Z","iopub.execute_input":"2021-10-21T17:36:10.069353Z","iopub.status.idle":"2021-10-21T17:36:10.090744Z","shell.execute_reply.started":"2021-10-21T17:36:10.069315Z","shell.execute_reply":"2021-10-21T17:36:10.089858Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"# shows what the prediction label does not fit to the real label\ntest_data[test_data['label'] != test_data['pred_label']].head()[['sentence','label','pred_label']].head(2)","metadata":{"id":"G08njojA4JMi","outputId":"26c450af-2f6a-4519-8659-e88811ef81d0","execution":{"iopub.status.busy":"2021-10-21T17:36:21.672954Z","iopub.execute_input":"2021-10-21T17:36:21.673279Z","iopub.status.idle":"2021-10-21T17:36:21.688671Z","shell.execute_reply.started":"2021-10-21T17:36:21.673242Z","shell.execute_reply":"2021-10-21T17:36:21.687391Z"},"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"markdown","source":"##### Predicted features of logistic regression model","metadata":{"id":"YQiIzf5nVKpy"}},{"cell_type":"code","source":"feature_to_coef = {word: float(\"%.3f\" % coef) for word, coef in zip(vectorizer.get_feature_names(), lr_clf.coef_[0])}\n\nprint(\"Top positive features:\")\nsorted(feature_to_coef.items(), key=lambda x: x[1], reverse=True)[:10]","metadata":{"id":"MxlhT5tE4VZC","outputId":"65905a02-3fc0-4c21-ff93-40d7d723a5af","execution":{"iopub.status.busy":"2021-10-21T17:36:42.599359Z","iopub.execute_input":"2021-10-21T17:36:42.600063Z","iopub.status.idle":"2021-10-21T17:36:42.620837Z","shell.execute_reply.started":"2021-10-21T17:36:42.600009Z","shell.execute_reply":"2021-10-21T17:36:42.619775Z"},"trusted":true},"execution_count":155,"outputs":[]},{"cell_type":"code","source":"# most of the words are reliable evidence of indicating negative sentiments\nprint(\"Top negative features:\")\nsorted(feature_to_coef.items(), key=lambda x: x[1], reverse=False)[:10]","metadata":{"id":"L-Zu8m4TQ_tl","outputId":"cf90936f-f1c4-4400-e522-6bb320e19291","execution":{"iopub.status.busy":"2021-10-21T17:36:45.390422Z","iopub.execute_input":"2021-10-21T17:36:45.391765Z","iopub.status.idle":"2021-10-21T17:36:45.403727Z","shell.execute_reply.started":"2021-10-21T17:36:45.391688Z","shell.execute_reply":"2021-10-21T17:36:45.402543Z"},"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"markdown","source":"##### Predicted features of BernouliNB","metadata":{"id":"__g2W9hzVSvI"}},{"cell_type":"code","source":"feature_to_coef = {word: float(\"%.3f\" % coef) for word, coef in zip(vectorizer.get_feature_names(), nb_clf.coef_[0])}\n\nprint(\"Top positive features:\")\nsorted(feature_to_coef.items(), key=lambda x: x[1], reverse=True)[:10]","metadata":{"id":"OZj7AYpyQPJP","outputId":"5cbfe450-d136-4aa8-dbf1-17f83c592a5e","execution":{"iopub.status.busy":"2021-10-21T17:36:49.924994Z","iopub.execute_input":"2021-10-21T17:36:49.925682Z","iopub.status.idle":"2021-10-21T17:36:49.944645Z","shell.execute_reply.started":"2021-10-21T17:36:49.925640Z","shell.execute_reply":"2021-10-21T17:36:49.943763Z"},"trusted":true},"execution_count":157,"outputs":[]},{"cell_type":"code","source":"# most of the words are reliable evidence of indicating negative sentiments\nprint(\"Top negative features:\")\nsorted(feature_to_coef.items(), key=lambda x: x[1], reverse=False)[:10]","metadata":{"id":"wCqxxw3RRBaw","outputId":"49a6ebbd-0858-4c99-bf6f-d13a6e87dc80","execution":{"iopub.status.busy":"2021-10-21T17:36:57.566264Z","iopub.execute_input":"2021-10-21T17:36:57.566911Z","iopub.status.idle":"2021-10-21T17:36:57.576566Z","shell.execute_reply.started":"2021-10-21T17:36:57.566871Z","shell.execute_reply":"2021-10-21T17:36:57.575661Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"markdown","source":"##### Predicted features of multinomial NB","metadata":{"id":"_dd9PlAKVASq"}},{"cell_type":"code","source":"feature_to_coef = {word: float(\"%.3f\" % coef) for word, coef in zip(vectorizer.get_feature_names(), mnb.coef_[0])}\n\nprint(\"Top positive features:\")\nsorted(feature_to_coef.items(), key=lambda x: x[1], reverse=True)[:10]","metadata":{"id":"sdxER_gxQPpp","outputId":"f201e97d-73e4-453e-aa02-93e7e4165a68","execution":{"iopub.status.busy":"2021-10-21T17:37:00.808163Z","iopub.execute_input":"2021-10-21T17:37:00.808477Z","iopub.status.idle":"2021-10-21T17:37:00.824934Z","shell.execute_reply.started":"2021-10-21T17:37:00.808440Z","shell.execute_reply":"2021-10-21T17:37:00.824041Z"},"trusted":true},"execution_count":159,"outputs":[]},{"cell_type":"code","source":"# most of the words are reliable evidence of indicating negative sentiments\nprint(\"Top negative features:\")\nsorted(feature_to_coef.items(), key=lambda x: x[1], reverse=False)[:10]","metadata":{"id":"kPa6sLvLvjbT","outputId":"f2704162-fa31-4d72-c5dc-099806de1666","execution":{"iopub.status.busy":"2021-10-21T17:37:03.872064Z","iopub.execute_input":"2021-10-21T17:37:03.872998Z","iopub.status.idle":"2021-10-21T17:37:03.882174Z","shell.execute_reply.started":"2021-10-21T17:37:03.872947Z","shell.execute_reply":"2021-10-21T17:37:03.881311Z"},"trusted":true},"execution_count":160,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion","metadata":{"id":"4enhxresvsZo"}},{"cell_type":"code","source":"text=['i want to make this positive', 'i want to make this project better', 'i feel aaaaaaah']\ntest_result = lr_clf.predict(vectorizer.transform(text))\nprint(test_result)","metadata":{"id":"sy7jHH-Fv18V","outputId":"afe23fff-68ed-42df-a1b4-0e0ba08093f5","execution":{"iopub.status.busy":"2021-10-21T17:37:17.339647Z","iopub.execute_input":"2021-10-21T17:37:17.340334Z","iopub.status.idle":"2021-10-21T17:37:17.346557Z","shell.execute_reply.started":"2021-10-21T17:37:17.340289Z","shell.execute_reply":"2021-10-21T17:37:17.345500Z"},"trusted":true},"execution_count":161,"outputs":[]},{"cell_type":"markdown","source":"The multinominal Naive Bayes model is slightly higher than Bernoulli Naive Bayes model.\nUsing the Logistic Regression model is the best model along with the three classifiers because it has the highest accuracy through this project. Also, the predicted features of the logistic regression model are most accurate and reasonable compare to other classifiers. By comparing the three classifiers, the logistic regression model has three to four higher accuracy than others.\n\nAccording to the Logistic Regression Model prediction, when people talk about their feeling that they are accepted, supported, and beloved, they use positive emojis when they are texting. On the other hand, when people feel pressured, hated, or punished, they use negative emojis when texting. \n","metadata":{"id":"iWzUgOkAvw5I"}}]}